import os
import re
import requests
from tqdm import tqdm
from time import sleep

file_name = input("Nh·∫≠p t√™n file ch·ª©a URL (v√≠ d·ª•: urls.txt): ").strip()

# Ki·ªÉm tra file t·ªìn t·∫°i
if not os.path.exists(file_name):
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {file_name}")
    exit()

# ƒê·ªçc to√†n b·ªô n·ªôi dung file
with open(file_name, 'r', encoding='utf-8') as f:
    content = f.read()

# T√¨m t·∫•t c·∫£ URL h·ª£p l·ªá b·∫±ng regex
urls = list(set(re.findall(r'https?://[^\s]+', content)))  # lo·∫°i b·ªè tr√πng

working_urls = []
broken_urls = []

headers = {'User-Agent': 'Mozilla/5.0'}

# Ki·ªÉm tra t·ª´ng URL
for url in tqdm(urls, desc="üîé ƒêang ki·ªÉm tra URL", unit="url"):
    for attempt in range(3):  # th·ª≠ 3 l·∫ßn n·∫øu l·ªói
        try:
            response = requests.head(url, headers=headers, timeout=5, allow_redirects=True)
            if response.status_code in [200, 301, 302, 403, 405]:
                working_urls.append(url)
            else:
                broken_urls.append(url)
            break  # n·∫øu th√†nh c√¥ng, tho√°t v√≤ng l·∫∑p th·ª≠
        except Exception as e:
            if attempt == 2:
                print(f"‚ö†Ô∏è L·ªói v·ªõi {url}: {e}")
                broken_urls.append(url)
            else:
                sleep(1)  # ƒë·ª£i 1 gi√¢y r·ªìi th·ª≠ l·∫°i

# Ghi k·∫øt qu·∫£ ra file
with open('working_urls.txt', 'w', encoding='utf-8') as f:
    f.writelines(url + '\n' for url in working_urls)

with open('broken_urls.txt', 'w', encoding='utf-8') as f:
    f.writelines(url + '\n' for url in broken_urls)

# Th·ªëng k√™
print("\n==== K·∫æT QU·∫¢ ====")
print(f"T·ªïng URL t√¨m th·∫•y: {len(urls)}")
print(f"‚úÖ H·ª£p l·ªá: {len(working_urls)}")
print(f"‚ùå B·ªã l·ªói: {len(broken_urls)}")
print("K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'working_urls.txt' v√† 'broken_urls.txt'")
